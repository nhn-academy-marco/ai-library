# Phase 1: 벡터 임베딩과 코사인 유사도

## 학습 개요

개인화 추천 시스템의 수학적 기초가 되는 **벡터 임베딩**과 **코사인 유사도**를 학습합니다. 도서를 1024차원 숫자 배열로 변환하는 방법과, 두 벡터 간의 유사도를 계산하는 방법을 이해합니다.

## 학습 목표

1. **임베딩의 개념 이해**
   - 텍스트를 숫자로 변환하는 이유와 방법
   - BGE-M3 모델의 구조와 특징
   - 1024차원 벡터가 의미하는 것

2. **코사인 유사도 수학적 정의**
   - 내적(Dot Product)과 벡터 크기(Norm)
   - 코사인 유사도 공식 유도
   - 유사도 값의 범위와 해석

3. **코드로 구현하는 코사인 유사도**
   - Java로 코사인 유사도 계산 함수 작성
   - 테스트 케이스로 검증

---

## 1. 벡터 임베딩(Vector Embedding)

### 1.1 임베딩이란?

**임베딩(Embedding)**은 텍스트, 이미지, 오디오 등의 데이터를 **숫자로 된 배열(벡터)**로 변환하는 기술입니다.

```
[텍스트 데이터]
"해리포터와 마법사의 돌"
      ↓ 임베딩 모델 (BGE-M3)
[벡터 데이터]
[0.12, -0.34, 0.56, 0.78, -0.23, ..., 0.45]  (1024개의 숫자)
```

**왜 임베딩을 사용하는가?**

1. **컴퓨터는 숫자만 이해한다**
   - 텍스트는 계산 불가능
   - 숫자는 덧셈, 뺄셈, 곱셈 가능

2. **의미 유사성을 수학적으로 표현**
   - 비슷한 내용 → 비슷한 벡터
   - 다른 내용 → 다른 벡터

### 1.2 BGE-M3 임베딩 모델

**BGE-M3**는 Beijing Academy of Artificial Intelligence에서 개발한 다국어 임베딩 모델입니다.

**특징:**
- **차원**: 1024차원 (1024개의 숫자로 표현)
- **입력**: 최대 8192 토큰 (긴 텍스트 처리 가능)
- **지원 언어**: 100개 이상의 언어 (한국어 포함)
- **용도**: 텍스트 검색, 의미 유사도 계산

**우리 시스템에서의 활용:**
```java
Book Entity
├── id: Long
├── title: String        → "해리포터와 마법사의 돌"
├── content: String      → "조앤 K. 롤링의 첫 번째 소설..."
└── embedding: float[1024]  → [0.12, -0.34, ..., 0.45]
```

### 1.3 벡터의 의미 이해

**의미 유사한 벡터끼리는 거리가 가깝다**

```
벡터1 (해리포터): [0.12, -0.34, 0.56, 0.78, ...]
벡터2 (마법사 돌):  [0.13, -0.33, 0.55, 0.77, ...]
→ 코사인 유사도: 0.98 (매우 비슷함)

벡터3 (주식 투자):  [-0.45, 0.67, -0.12, 0.23, ...]
→ 코사인 유사도: 0.23 (덜 비슷함)
```

**직관적 이해:**
- 1024차원 공간에서의 좌표
- 비슷한 주제의 도서들은 가까운 위치
- 다른 주제의 도서들은 먼 위치

---

## 2. 코사인 유사도(Cosine Similarity)

### 2.1 기하학적 직관

**코사인 유사도**는 두 벡터가 **얼마나 같은 방향을 가리키는지**를 측정합니다.

```
        B
       /
      /
     / θ ← 두 벡터 사이의 각도
    /
   O─────── A
```

- **θ = 0°** (같은 방향): `cosine_similarity = 1.0` (최대)
- **θ = 90°** (직각): `cosine_similarity = 0.0` (무관계)
- **θ = 180°** (반대 방향): `cosine_similarity = -1.0` (최소)

### 2.2 수학적 정의

```
cosine_similarity(A, B) = (A · B) / (||A|| × ||B||)

A · B = Σ(ai × bi)             (내적, Dot Product)
||A|| = √(Σ(ai²))              (벡터 A의 크기, Norm)
```

**용어 설명:**

1. **내적(Dot Product, A · B)**
   - 두 벡터의 같은 위치의 값을 곱해서 모두 더함
   - 예: `[1, 2, 3] · [4, 5, 6] = (1×4) + (2×5) + (3×6) = 32`

2. **벡터 크기(Norm, ||A||)**
   - 원점부터 벡터 끝점까지의 거리
   - 피타고라스 정리 확장
   - 예: `||[1, 2, 3]|| = √(1² + 2² + 3²) = √14 ≈ 3.74`

### 2.3 계산 예시

**예제 1: 완전히 같은 벡터**
```
A = [1, 2, 3]
B = [1, 2, 3]

A · B = 1×1 + 2×2 + 3×3 = 14
||A|| = √(1 + 4 + 9) = √14
||B|| = √(1 + 4 + 9) = √14

cosine_similarity = 14 / (√14 × √14) = 14 / 14 = 1.0
```

**예제 2: 반대 방향 벡터**
```
A = [1, 2, 3]
B = [-1, -2, -3]

A · B = (1×-1) + (2×-2) + (3×-3) = -14
||A|| = √14
||B|| = √14

cosine_similarity = -14 / (√14 × √14) = -14 / 14 = -1.0
```

**예제 3: 직각 벡터**
```
A = [1, 0, 0]
B = [0, 1, 0]

A · B = (1×0) + (0×1) + (0×0) = 0
||A|| = 1
||B|| = 1

cosine_similarity = 0 / (1 × 1) = 0.0
```

---

## 3. 코드로 구현하는 코사인 유사도

### 3.1 Java 구현

```java
/**
 * 벡터 연산 유틸리티
 */
public class VectorUtils {

    /**
     * 두 벡터 간의 코사인 유사도를 계산합니다.
     *
     * @param v1 첫 번째 벡터 (1024차원)
     * @param v2 두 번째 벡터 (1024차원)
     * @return 코사인 유사도 (-1.0 ~ 1.0)
     * @throws IllegalArgumentException 벡터 길이가 다른 경우
     */
    public static double cosineSimilarity(float[] v1, float[] v2) {
        if (v1.length != v2.length) {
            throw new IllegalArgumentException(
                "벡터 길이가 같아야 합니다: v1=" + v1.length + ", v2=" + v2.length
            );
        }

        double dotProduct = 0.0;   // 내적
        double norm1 = 0.0;        // v1의 크기
        double norm2 = 0.0;        // v2의 크기

        // 한 번의 루프로 세 값 모두 계산
        for (int i = 0; i < v1.length; i++) {
            dotProduct += v1[i] * v2[i];
            norm1 += v1[i] * v1[i];
            norm2 += v2[i] * v2[i];
        }

        // 0으로 나누기 방지
        if (norm1 == 0.0 || norm2 == 0.0) {
            return 0.0;
        }

        return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
    }
}
```

### 3.2 테스트 코드

```java
import org.junit.jupiter.api.Test;
import static org.junit.jupiter.api.Assertions.*;

class VectorUtilsTest {

    @Test
    void testCosineSimilarity_IdenticalVectors() {
        float[] v1 = {1.0f, 2.0f, 3.0f};
        float[] v2 = {1.0f, 2.0f, 3.0f};

        double similarity = VectorUtils.cosineSimilarity(v1, v2);

        assertEquals(1.0, similarity, 0.0001);
    }

    @Test
    void testCosineSimilarity_OppositeVectors() {
        float[] v1 = {1.0f, 2.0f, 3.0f};
        float[] v2 = {-1.0f, -2.0f, -3.0f};

        double similarity = VectorUtils.cosineSimilarity(v1, v2);

        assertEquals(-1.0, similarity, 0.0001);
    }

    @Test
    void testCosineSimilarity_OrthogonalVectors() {
        float[] v1 = {1.0f, 0.0f, 0.0f};
        float[] v2 = {0.0f, 1.0f, 0.0f};

        double similarity = VectorUtils.cosineSimilarity(v1, v2);

        assertEquals(0.0, similarity, 0.0001);
    }

    @Test
    void testCosineSimilarity_RealExample() {
        // 해리포터 관련 벡터 (예시)
        float[] harryPotter = {0.5f, 0.8f, 0.3f, 0.9f, 0.2f};

        // 마법사 관련 벡터 (예시)
        float[] magicBook = {0.6f, 0.7f, 0.4f, 0.8f, 0.3f};

        // 주식 투자 관련 벡터 (예시)
        float[] stockBook = {-0.3f, 0.2f, -0.5f, 0.1f, 0.9f};

        double similarity1 = VectorUtils.cosineSimilarity(harryPotter, magicBook);
        double similarity2 = VectorUtils.cosineSimilarity(harryPotter, stockBook);

        // 해리포터와 마법사가 더 유사해야 함
        assertTrue(similarity1 > similarity2);
        assertTrue(similarity1 > 0.8);  // 매우 유사
        assertTrue(similarity2 < 0.5);  // 덜 유사
    }
}
```

---

## 4. 실전 활용: 도서 유사도 계산

### 4.1 Book 엔티티 구조 확인

```java
@Entity
@Table(name = "books")
public class Book {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    private String title;
    private String content;

    @Column(name = "embedding", columnDefinition = "float[1024]")
    private float[] embedding;  // BGE-M3 벡터
}
```

### 4.2 도서별 유사도 계산 예시

```java
@Service
public class BookSimilarityService {

    private final BookRepository bookRepository;

    /**
     * 두 도서 간의 유사도를 계산합니다.
     */
    public double calculateSimilarity(Long bookId1, Long bookId2) {
        Book book1 = bookRepository.findById(bookId1)
            .orElseThrow(() -> new IllegalArgumentException("도서 not found: " + bookId1));
        Book book2 = bookRepository.findById(bookId2)
            .orElseThrow(() -> new IllegalArgumentException("도서 not found: " + bookId2));

        return VectorUtils.cosineSimilarity(
            book1.getEmbedding(),
            book2.getEmbedding()
        );
    }

    /**
     * 특정 도서와 가장 유사한 도서 TOP N을 찾습니다.
     */
    public List<Book> findMostSimilarBooks(Long bookId, int topN) {
        Book targetBook = bookRepository.findById(bookId)
            .orElseThrow(() -> new IllegalArgumentException("도서 not found: " + bookId));

        List<Book> allBooks = bookRepository.findAll();

        // 유사도 계산 후 정렬
        return allBooks.stream()
            .filter(book -> !book.getId().equals(bookId))  // 자기 자신 제외
            .map(book -> Map.entry(
                book,
                VectorUtils.cosineSimilarity(
                    targetBook.getEmbedding(),
                    book.getEmbedding()
                )
            ))
            .sorted((e1, e2) -> Double.compare(e2.getValue(), e1.getValue()))  // 내림차순
            .limit(topN)
            .map(Map.Entry::getKey)
            .collect(Collectors.toList());
    }
}
```

---

## 5. 데이터베이스에서 임베딩 확인

### 5.1 PostgreSQL에서 임베딩 조회

```sql
-- 도서 ID와 제목, 임베딩의 첫 5개 값 확인
SELECT
    id,
    title,
    embedding[1:5] as first_5_values,
    array_length(embedding, 1) as dimension
FROM books
LIMIT 5;
```

**결과 예시:**
```
 id |        title        | first_5_values                  | dimension
----+---------------------+---------------------------------+----------
  1 | 해리포터와 마법사의 돌  | {0.12,-0.34,0.56,0.78,-0.23}    |     1024
  2 | 주식으로 돈 버는 법     | {-0.45,0.67,-0.12,0.23,0.89}    |     1024
  3 | 스프링 부트 입문        | {0.34,0.21,-0.56,0.12,0.45}    |     1024
```

### 5.2 pgvector로 유사도 계산 (SQL)

PostgreSQL의 `pgvector` 확장을 사용하면 SQL로 직접 코사인 유사도를 계산할 수 있습니다.

```sql
-- id=1인 도서와 가장 유사한 도서 5개 찾기
SELECT
    id,
    title,
    1 - (embedding <=> (
        SELECT embedding FROM books WHERE id = 1
    )) as similarity
FROM books
WHERE id != 1
ORDER BY embedding <=> (SELECT embedding FROM books WHERE id = 1)
LIMIT 5;
```

**참고:**
- `<=>` 연산자: **음의 코사인 거리** (값이 작을수록 유사)
- `1 - (embedding <=> embedding)`: 코사인 유사도로 변환 (값이 클수록 유사)

---

## 학습 요약

### 핵심 개념

1. **임베딩(Embedding)**
   - 텍스트를 숫자 배열로 변환
   - 의미 유사성을 수학적으로 표현
   - BGE-M3: 1024차원 벡터 생성

2. **코사인 유사도(Cosine Similarity)**
   - 두 벡터 간의 각도로 유사도 측정
   - 범위: -1.0 (반대) ~ 1.0 (같음)
   - 공식: `(A · B) / (||A|| × ||B||)`

3. **구현**
   - Java로 3가지 값 계산: 내적, 두 벡터의 크기
   - 한 번의 루프로 효율적으로 계산
   - 0으로 나누기 방지 처리 필수

### 다음 단계

이제 벡터와 코사인 유사도의 기초를 이해했습니다. 다음 단계에서는:

**[02. 사용자 선호도 벡터 계산](./02.user-preference-vector.md)**

- 사용자가 좋아한 도서들의 임베딩을 어떻게 평균 낼까요?
- GOOD 피드백 도서들을 어떻게 추출할까요?
- 평균 벡터가 어떻게 사용자의 취향을 나타낼까요?

---

## 연습 문제

### 문제 1: 코사인 유사도 계산

다음 두 벡터의 코사인 유사도를 계산하세요.

```
A = [2, 4, 6]
B = [4, 8, 12]
```

<details>
<summary>정답 보기</summary>

```
A · B = 2×4 + 4×8 + 6×12 = 8 + 32 + 72 = 112
||A|| = √(4 + 16 + 36) = √56
||B|| = √(16 + 64 + 144) = √224

cosine_similarity = 112 / (√56 × √224)
                  = 112 / √12544
                  = 112 / 112
                  = 1.0
```

B는 A의 2배이므로 방향이 같아 유사도는 1.0입니다.
</details>

### 문제 2: 벡터 평균 계산

다음 세 벡터의 평균을 계산하세요.

```
v1 = [1, 2, 3]
v2 = [4, 5, 6]
v3 = [7, 8, 9]
```

<details>
<summary>정답 보기</summary>

```
평균[0] = (1 + 4 + 7) / 3 = 12 / 3 = 4
평균[1] = (2 + 5 + 8) / 3 = 15 / 3 = 5
평균[2] = (3 + 6 + 9) / 3 = 18 / 3 = 6

결과: [4, 5, 6]
```
</details>

---

**다음**: [02. 사용자 선호도 벡터 계산](./02.user-preference-vector.md) →
