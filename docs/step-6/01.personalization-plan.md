# Step 6: 개인화 추천 시스템

## 학습 개요

Step 5에서 수집한 **사용자 피드백 데이터를 활용**하여, 사용자별로 맞춤화된 도서 추천 시스템을 구축합니다. 사용자가 좋아한 도서들의 임베딩 벡터를 분석하여 선호도를 학습하고, 이를 검색 결과에 반영합니다.

## 학습 목표

1. **벡터 임베딩과 코사인 유사도 이해**
   - 도서 콘텐츠를 1024차원 벡터로 변환하는 BGE-M3 모델 이해
   - 벡터 간 유사도를 코사인 유사도로 계산하는 방법 학습
   - 벡터 평균으로 사용자 선호도 표현하는 방법 습득

2. **사용자 선호도 학습 방법**
   - GOOD 피드백이 많은 도서들의 임베딩 평균 계산
   - 평균 벡터를 사용자의 취향으로 해석
   - 콜드 스타트(Cold Start) 문제와 해결 방안 이해

3. **검색 결과 개인화 재정렬**
   - 기존 RRF 점수 + 선호도 유사도 조합
   - 가중치 파라미터(0.3)를 통한 기존 검색 결과 존중
   - 개인화된 순위로 결과 재정렬

4. **익명 사용자 환경에서의 개인화**
   - 로그인 없이 chatId만으로 개인화 구현
   - 세션 기반 개인화의 한계와 장점 이해

---

## 전체 시스템 아키텍처

### 1. 기존 검색 시스템 (Step 1-5)

```
[사용자 검색]
    ↓
[BookSearchService]
    ↓
[HybridSearchStrategy]
    ├─ Keyword Search (전체 텍스트 검색)
    └─ Vector Search (임베딩 유사도 검색)
    ↓
[RRF(Reciprocal Rank Fusion)]
    └─ 두 검색 결과 병합 → 순위 계산
    ↓
[검색 결과 반환]
```

### 2. 개인화가 적용된 검색 시스템 (Step 6)

```
[사용자 검색]
    ↓
[PersonalizationService]
    ├─ chatId로 피드백 조회
    ├─ GOOD 피드백 도서 ID 추출
    ├─ BookRepository에서 임베딩 조회
    └─ 평균 벡터 계산 (사용자 선호도)
    ↓
[HybridSearchStrategy]
    ├─ Keyword Search
    └─ Vector Search
    ↓
[RRF]
    └─ 기존 검색 결과 병합
    ↓
[개인화 재정렬]
    ├─ 각 도서별 선호 벡터와의 유사도 계산
    ├─ 최종 점수 = RRF 점수 + (유사도 × 0.3)
    └─ 재정렬
    ↓
[개인화된 검색 결과 반환]
```

---

## 핵심 개념 상세 설명

### 1. 벡터 임베딩(Vector Embedding)

#### 1.1 임베딩이란?

텍스트를 숫자로 된 배열(벡터)로 변환하는 기술입니다.

```
[텍스트]
"해리포터와 마법사의 돌"
      ↓ 임베딩 모델 (BGE-M3)
[벡터]
[0.12, -0.34, 0.56, ..., 0.78]  (1024차원)
```

**의미 유사한 벡터끼리는 의미도 비슷함**
```
벡터1 (해리포터): [0.12, -0.34, 0.56, ...]
벡터2 (마법사 돌):  [0.13, -0.33, 0.55, ...]
→ 코사인 유사도: 0.98 (매우 비슷함)

벡터3 (주식 투자):  [-0.45, 0.67, -0.12, ...]
→ 코사인 유사도: 0.23 (덜 비슷함)
```

#### 1.2 우리 시스템의 임베딩 구조

```
Book Entity
├── id: Long
├── title: String
├── content: String
└── embedding: float[1024]  ← BGE-M3 벡터 컬럼
```

**데이터베이스에 이미 저장되어 있음!**
- Step 2에서 도서 등록 시 생성
- pgvector 확장 기능으로 저장
- 1024차원 float[] 배열

### 2. 코사인 유사도(Cosine Similarity)

#### 2.1 수학적 정의

```
cosine_similarity(A, B) = (A · B) / (||A|| × ||B||)

A · B = Σ(ai × bi)           (내적, Dot Product)
||A|| = √(Σ(ai²))            (벡터 A의 크기, Norm)
```

**직관적 이해:**
```
벡터 각각 방향이 얼마나 비슷한가?

[완전히 같은 방향]
cosine_similarity([1, 2, 3], [1, 2, 3]) = 1.0

[반대 방향]
cosine_similarity([1, 2, 3], [-1, -2, -3]) = -1.0

[직각]
cosine_similarity([1, 0, 0], [0, 1, 0]) = 0.0
```

#### 2.2 코드로 보는 코사인 유사도

```java
private double cosineSimilarity(float[] v1, float[] v2) {
    double dotProduct = 0.0;   // 내적
    double norm1 = 0.0;        // v1의 크기
    double norm2 = 0.0;        // v2의 크기

    for (int i = 0; i < v1.length; i++) {
        dotProduct += v1[i] * v2[i];
        norm1 += v1[i] * v1[i];
        norm2 += v2[i] * v2[i];
    }

    return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
}
```

### 3. 벡터 평균으로 사용자 선호도 표현

#### 3.1 개념

```
사용자 A가 좋아한 도서:
1. "해리포터와 마법사의 돌" → embedding1
2. "해리포터와 비밀의 방"   → embedding2
3. "판타지 소설"           → embedding3

사용자 A의 선호 벡터:
(embedding1 + embedding2 + embedding3) / 3

→ "판타지", "마법", "모험" 키워드를 선호하는 사용자
```

#### 3.2 평균 벡터 계산 흐름

```
[Step 1] GOOD 피드백 도서 ID 추출
feedbackService.getUserFeedback(chatId)
  → GOOD 피드백만 필터링
  → 최근 20개 제한
  → bookIds = [101, 102, 305, ...]

[Step 2] 임베딩 조회
bookRepository.findEmbeddingsByIds(bookIds)
  → SELECT embedding FROM books WHERE id IN (...)
  → [[0.1, 0.2, ...], [0.3, 0.4, ...], ...]

[Step 3] 평균 계산
각 차원별로 평균 계산
  → result[0] = (emb1[0] + emb2[0] + ...) / count
  → result[1] = (emb1[1] + emb2[1] + ...) / count
  ...

[Step 4] 사용자 선호 벡터 완성
return result  // float[1024]
```

---

## 개인화 파이프라인 상세 분석

### Phase 1: 도서별 피드백 점수화

#### 목표
전체 사용자의 피드백을 종합하여 도서별 점수를 계산합니다.

#### 구현

```java
public Map<Long, Double> calculateBookFeedbackScores(List<Long> bookIds) {
    Map<Long, Double> scores = new HashMap<>();

    for (Long bookId : bookIds) {
        List<SearchFeedback> feedbacks =
            feedbackRepository.findByBookId(bookId);

        if (feedbacks.isEmpty()) {
            scores.put(bookId, 0.0);
            continue;
        }

        long goodCount = feedbacks.stream()
            .filter(f -> f.getType() == FeedbackType.GOOD)
            .count();

        long badCount = feedbacks.stream()
            .filter(f -> f.getType() == FeedbackType.BAD)
            .count();

        double score = (double)(goodCount - badCount) / feedbacks.size();
        scores.put(bookId, score);
    }

    return scores;
}
```

**점수 해석:**
```
score = 1.0  → 모두 GOOD (100% 긍정)
score = 0.5  → 75% GOOD, 25% BAD
score = 0.0  → 50% GOOD, 50% BAD
score = -0.5 → 25% GOOD, 75% BAD
score = -1.0  → 모두 BAD (0% 긍정)
```

### Phase 2: 사용자 선호 벡터 계산

#### 목표
사용자가 좋아한 도서들의 임베딩 평균으로 선호도를 벡터화합니다.

#### 구현

```java
public float[] calculateUserPreferenceVector(Long chatId) {
    // 1. GOOD 피드백만 조회
    List<SearchFeedback> feedbacks = feedbackService.getUserFeedback(chatId);

    List<Long> likedBookIds = feedbacks.stream()
        .filter(f -> f.getType() == FeedbackType.GOOD)
        .map(SearchFeedback::getBookId)
        .distinct()
        .limit(20)  // 최근 20개만
        .collect(Collectors.toList());

    // 2. 최소 3개 이상이어야 개인화
    if (likedBookIds.size() < 3) {
        return null;  // 콜드 스타트
    }

    // 3. 임베딩 조회
    List<float[]> embeddings = bookRepository.findEmbeddingsByIds(likedBookIds);

    // 4. 평균 계산
    return calculateAverageVector(embeddings);
}
```

**콜드 스타트(Cold Start) 문제:**
```
신규 사용자: 피드백 0개
해결: 피드백 3개 이상 시 개인화 시작
그 전까지는 일반 검색 결과 반환
```

### Phase 3: 개인화 재정렬

#### 목표
RRF 점수 + 선호도 유사도를 조합하여 최종 순위를 결정합니다.

#### 점수 계산 공식

```
최종 점수 = RRF 점수 + (선호도 유사도 × 0.3)

예:
도서 A: RRF=0.025, 유사도=0.8
→ 최종 = 0.025 + (0.8 × 0.3) = 0.025 + 0.24 = 0.265

도서 B: RRF=0.030, 유사도=0.2
→ 최종 = 0.030 + (0.2 × 0.3) = 0.030 + 0.06 = 0.090
→ 도서 B가 더 높음
```

**왜 가중치 0.3인가?**
- 기존 검색 결과를 존중 (0.7)
- 개인화 효과를 제한적으로 반영 (0.3)
- 사용자가 새로운 책도 발견할 수 있도록 함

---

## 데이터베이스 추가 구조

### BookRepository 확장

```java
public interface BookRepository extends JpaRepository<Book, Long> {

    /**
     * 도서 ID 목록으로 임베딩 조회
     *
     * @param bookIds 도서 ID 목록
     * @return 임베딩 리스트 (float[1024][])
     */
    @Query("SELECT b.embedding FROM Book b WHERE b.id IN :bookIds")
    List<float[]> findEmbeddingsByIds(@Param("bookIds") List<Long> bookIds);
}
```

**SQL 실행 예시:**
```sql
SELECT embedding
FROM books
WHERE id IN (101, 102, 305, 407, 512);
```

---

## 제약사항과 해결 방안

### 1. 익명 사용자 환경

**제약:**
- 로그인 없음
- chatId만 식별자
- Bot 재설치 시 chatId 변경 가능

**해결:**
```
1. 단기 세션으로 취급
2. 주기적 데이터 정리 (예: 6개월 이상 피드백 삭제)
3. PrivacyUtil로 chatId 마스킹 처리 (로그 표시)
```

### 2. 성능 고려사항

**문제:**
- 매 검색마다 선호 벡터 계산은 느림

**해결:**
```
1. 선호 벡터 캐싱
   - Redis에 저장
   - TTL: 24시간
   - 피드백 새로 올 때마다 갱신

2. 비동기 계산
   - 검색 결과 반환 즉시
   - 백그라운드에서 선호 벡터 계산
   - 다음 검색부터 반영
```

### 3. 콜드 스타트(Cold Start)

**문제:**
- 신규 사용자는 피드백이 없어 개인화 불가

**해결:**
```
if (피드백 < 3개) {
    // 1. 전체 인기도 반영
    float globalScore = calculateGlobalPopularity(bookId);

    // 2. 안내 메시지
    "📊 더 좋은 추천을 위해 피드백을 남겨주세요!"
}
```

---

## 구현 Phase별 가이드

### Phase 1: 도서별 피드백 점수화 (2-3시간)

**목표:** 각 도서별 피드백 점수를 계산

**구현 항목:**
1. `BookFeedbackScoreService` 클래스 생성
2. `calculateBookFeedbackScores()` 메서드 구현
3. 단위 테스트 작성

**기대 효과:**
```
검색: "자바"
도서 A: 피드백 점수 +0.5 → 상위 노출
도서 B: 피드백 점수 -0.2 → 하위 노출
```

### Phase 2: 사용자 선호 벡터 계산 (3-4시간)

**목표:** 사용자별 선호 벡터 생성

**구현 항목:**
1. `PersonalizationService` 클래스 생성
2. `calculateUserPreferenceVector()` 메서드 구현
3. `BookRepository.findEmbeddingsByIds()` 쿼리 추가
4. `calculateAverageVector()` 헬퍼 메서드 구현

**기대 효과:**
```
사용자 A: "판타지" 좋아요 → 판타지 벡터 학습
검색: "도서 추천" → 판타지 관련 도서 상위 노출
```

### Phase 3: 검색 결과 개인화 (1시간)

**목표:** 기존 검색 서비스에 개인화 로직 추가

**구현 항목:**
1. `LibraryTelegramBot.handleSearch()` 수정
2. `PersonalizationService.personalizedSearch()` 호출
3. 개인화 여부 UI 표시

---

## 학습 체크리스트

### 핵심 개념 이해

- [ ] 벡터 임베딩이 무엇인지 설명할 수 있다
- [ ] 코사인 유사도를 계산할 수 있다
- [ ] 벡터 평균으로 사용자 선호도를 표현할 수 있다
- [ ] RRF 알고리즘을 이해한다

### 구현 능력

- [ ] 사용자별 GOOD 피드백 도서 추출 가능
- [ ] 임베딩 평균 계산 가능
- [ ] 코사인 유사도 기반 재정렬 가능
- [ ] 가중치 파라미터 조절 가능

### 제약사항 이해

- [ ] 콜드 스타트 문제와 해결 방안 안다
- [ ] Telegram chatId 한계와 이해
- [ ] 성능 최적화 방법 (캐싱, 비동기)

---

## 참고 자료

- [Vector Embeddings for Recommendations](https://www.pinecone.io/learn/vector-recommendations/)
- [Collaborative Filtering vs Content-Based](https://www.datasciencecentral.com/collaborative-filtering-vs-content-based-recommendations/)
- [Cold Start Problem in Recommender Systems](https://arxiv.org/abs/1907.01155)
- [Cosine Similarity for Recommendations](https://www.sciencedirect.com/science/article/pii/S1877050920316842)

---

## 다음 단계

**Step 6 완료 시 예상 결과:**

1. **도서별 피드백 점수** - 전체 사용자 피드백 반영
2. **사용자 선호도 학습** - 좋아한 도서들의 임베딩 평균
3. **개인화 검색 결과** - RRF + 선호도 유사도 조합

**구현 후 테스트 시나리오:**
```
[Before]
검색: "자바"
결과: 일반적인 인기 자바 도서들

[After]
검색: "자바" (사용자가 "웹 개발" 좋아함)
결과: 스프링, 웹 프레임워크 관련 자바 도서 상위 노출
```
