# 02. Top-K 및 Context 최적화 (실습 가이드)

## 1. 실습 개요

이전 단계에서 우리는 하이브리드 검색을 통해 도서를 찾아내고, 그 결과를 LLM에게 전달하여 답변을 생성하는 RAG 시스템을 구축했습니다. 하지만 현재 시스템은 모든 검색 결과를 그대로 LLM에게 전달하거나, UI의 페이징 크기에 의존하고 있어 비용과 성능 면에서 비효율적입니다.

이번 실습에서는 **Top-K 튜닝**과 **Context 최적화**를 통해 AI 응답의 품질을 높이고 비용을 절감하는 실질적인 로직을 구현합니다.

---

## 2. [미션 1] Retrieval K와 Rerank K의 분리

현재 우리 시스템은 `pageSize`에 따라 검색된 결과를 그대로 LLM에게 보냅니다. 하지만 검색 엔진에서 충분한 후보군을 뽑는 것(Retrieval)과, LLM이 집중해서 읽어야 할 최상위 문서를 고르는 것(Rerank)은 분리되어야 합니다.

### 구현 목표
- 검색 엔진에서는 충분한 양(예: 100개)의 데이터를 가져오되(Retrieval K),
- LLM에게는 그중 가장 관련성이 높은 최상위 N개만 전달하도록(Rerank K) 코드를 수정합니다.

### 가이드 (BookSearchService.java)
1. `generateAiResponse` 메서드 호출 시, 전체 리스트가 아닌 상위 `K`개만 슬라이싱하여 전달하도록 수정하세요.
2. `K`값은 질문의 성격에 따라 다를 수 있지만, 기본적으로 5~10 사이의 값을 권장합니다.

```java
// 변경 전
aiResponse = generateAiResponse(request.keyword(), results.getContent());

// 변경 후 (예시: 상위 5개만 선별)
List<BookSearchResponse> topKBooks = results.getContent().stream()
    .limit(5) 
    .toList();
aiResponse = generateAiResponse(request.keyword(), topKBooks);
```

---

## 3. [미션 2] RRF Score Threshold 필터링

단순히 상위 N개를 가져오는 것보다 중요한 것은 **"관련 없는 정보는 과감히 버리는 것"**입니다. RRF 점수가 너무 낮은 문서는 오히려 LLM에게 혼란(Noise)을 줄 수 있습니다.

### 구현 목표
- RRF 점수가 특정 임계값(Threshold) 이하인 도서는 검색 결과에는 포함되더라도, AI 컨텍스트에서는 제외하는 로직을 추가합니다.

### 가이드 (BookSearchService.java)
1. `generateAiResponse`에 데이터를 넘기기 전, `rrfScore`를 체크하는 로직을 추가하세요.
2. 실습 시 임계값은 `0.02` 정도로 설정해보고 결과의 변화를 관찰하세요.

```java
// 예시 로직
double THRESHOLD = 0.02;
List<BookSearchResponse> filteredBooks = results.getContent().stream()
    .filter(b -> b.getRrfScore() >= THRESHOLD)
    .limit(5)
    .toList();
```

---

## 4. [미션 3] Context 재구성 (Lost in the Middle 방지)

LLM은 컨텍스트의 **처음과 끝**에 있는 정보를 더 잘 처리하고, 중간에 있는 정보는 놓치는 경향이 있습니다. 이를 'Lost in the Middle' 현상이라고 합니다.

### 구현 목표
- 가장 중요한 문서(RRF 점수가 가장 높은 문서)를 컨텍스트의 가장 앞부분에 배치하여 LLM이 이를 최우선적으로 참고하게 합니다.

### 가이드
1. 현재 `generateAiResponse` 내부에서 `StringBuilder context`를 만드는 순서가 RRF 점수 내림차순인지 확인하세요.
2. 필요하다면 `results.getContent()`를 점수 기반으로 다시 한 번 정렬한 뒤 `StringBuilder`에 추가하세요.

---

## 5. [심화 미션] 의도 기반 동적 K 설정 (구현 예시)

사용자의 질문이 "단순한 사실 확인"인지 "종합적인 요약"인지에 따라 필요한 문서의 개수가 다릅니다. 우리 프로젝트의 구조에서 이를 구현하는 구체적인 방법은 다음과 같습니다.

### 구현 목표
- `BookAiService`에 질문의 의도를 분류하는 메서드를 추가합니다.
- `BookSearchService`에서 검색 전에 의도를 먼저 파악하고, 그에 따라 `K`값을 동적으로 결정합니다.

### step 1. 의도 분류 로직 추가 (BookAiService.java)
질문이 요약을 원하는지(SUMMARY), 단순 정보를 원하는지(SIMPLE) 분류하는 프롬프트를 작성합니다.

```java
public String classifyIntent(String question) {
    String intentPrompt = """
        사용자의 질문을 분석하여 다음 두 가지 카테고리 중 하나로 분류하세요:
        - SUMMARY: 여러 권의 도서를 비교하거나, 전반적인 추천 또는 요약을 원하는 경우
        - SIMPLE: 특정 도서의 상세 정보나 1~2권의 짧은 답변을 원하는 경우
        
        결과는 반드시 'SUMMARY' 또는 'SIMPLE' 중 하나의 단어로만 답변하세요.
        
        질문: %s
        """.formatted(question);
    return askAboutBooks(intentPrompt).trim().toUpperCase();
}
```

### step 2. 검색 서비스에 적용 (BookSearchService.java)
의도에 따라 `limit` 값을 변경합니다.

```java
// searchBooks 메서드 내부 예시
String intent = bookAiService.classifyIntent(request.keyword());
int dynamicK = intent.equals("SUMMARY") ? 10 : 3;

List<BookSearchResponse> topKBooks = results.getContent().stream()
    .filter(b -> b.getRrfScore() >= 0.02)
    .limit(dynamicK) // 동적으로 결정된 K 적용
    .toList();

aiResponse = generateAiResponse(request.keyword(), topKBooks);
```

---

## 6. 학습 포인트 (정리)

1.  **Trade-off**: K가 너무 작으면 정답을 놓칠 수 있고, 너무 크면 비용이 늘고 답변이 흐릿해집니다.
2.  **Noise Reduction**: 관련 없는 문서를 제거하는 것이 답변의 정확도(Hallucination 방지)에 직접적인 영향을 줍니다.
3.  **Efficiency**: 토큰을 아끼는 것은 곧 서비스의 지속 가능성(비용)과 직결됩니다.
