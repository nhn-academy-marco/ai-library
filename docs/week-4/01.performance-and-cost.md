# 01. 성능과 비용: AI 서비스의 현실적인 문제

## 학습 전제조건

이 문서를 학습하기 전에 다음 내용을 알고 있으면 도움이 됩니다:
- Week 1~3의 모든 문서 내용
- API 호출과 응답 시간 이해
- 기본적인 비용 계산 능력
- 성능 모니터링 개념

---

## 1. 개요

AI 서비스를 실제로 운영하면 생각지 못한 문제들이 발생합니다. 응답이 너무 늦거나, 비용이 너무 많이 드는 문제입니다.

**이 문서에서 배울 내용:**
- 응답 지연(Latency)이 무엇인지
- AI 서비스의 비용 구조
- 토큰과 비용의 관계
- 모델별 가격 정책
- 성능과 비용의 균형 잡기

> **중요: AI 서비스의 현실**
>
> 기대:
> - "AI가 1초만에 답변해줘!"
> - "비용은 거의 안 들어!"
>
> 현실:
> - 응답까지 3~5초 걸림
> - 1000명이 사용하면 비용 $50
>
> 현실적인 문제를 이해하고 최적화해야 합니다!

---

## 2. 핵심 개념 이해

### 2.1. 응답 지연 (Latency)

사용자가 질문하고 AI가 답변할 때까지 걸리는 시간입니다.

**비유로 이해하기:**
```
[일반적인 검색]
사용자: "자바 책" → 검색 → 0.1초 후 결과
→ 매우 빠름

[RAG 검색]
사용자: "초보자를 위한 자바 책"
→ 검색: 0.5초
→ 임베딩: 0.3초
→ AI 호출: 2초
→ 총 2.8초
→ 느림

사용자 입장:
- 2.8초 = 꽤 기다려야 함
- 5초 이상이면 답답함
```

**지연 시간 구성:**
```
총 지연 시간 = 검색 시간 + 임베딩 시간 + AI 생성 시간

[검색]
하이브리드 검색: 200~500ms
→ DB 쿼리 + 벡터 계산

[임베딩]
검색어를 벡터로 변환: 100~300ms
→ AI 임베딩 모델 호출

[AI 생성]
Chat Completion: 1~3초
→ 응답 생성 시간 (가장 큰 비중)
```

### 2.2. 토큰과 비용

AI는 텍스트를 토큰 단위로 처리하고, 토큰 수에 따라 비용이 청구됩니다.

**비유로 이해하기:**
```
[토큰이란?]
AI에게는 텍스트가 "토큰"이라는 단위로 보여요

예시:
"안녕하세요" → 5토큰
"자바의 정석을 추천합니다" → 12토큰
"초보자를 위한 자바 프로그래밍 입문서입니다..." → 25토큰

[비용 계산]
카펼를 생각해 보세요:
- 작은 커피: 5,000원 (토큰 100개)
- 큰 커피: 10,000원 (토큰 200개)
- 프라푸치노: 15,000원 (토큰 300개)
```

**비용 구조:**
```
총 비용 = 입력 토큰 비용 + 출력 토큰 비용

[입력 토큰]
프롬프트 + 컨텍스트
- 1,000토큰 × $0.0001 = $0.10

[출력 토큰]
AI가 생성한 답변
- 500토큰 × $0.0002 = $0.10

[총비용]
$0.10 + $0.10 = $0.20

사용자 1000명이면:
$0.20 × 1000 = $200
```

### 2.3. 모델별 가격 차이

모델마다 성능과 가격이 다릅니다.

**비교표 (Gemini 기준):**

| 모델 | 입력 (1M토큰) | 출력 (1M토큰) | 특징 |
|------|---------------|---------------|------|
| Gemini 2.0 Flash | $0.10 | $0.40 | 빠르고 저렴 |
| Gemini 1.5 Flash | $0.075 | $0.30 | 가장 저렴함 |
| Gemini 1.5 Pro | $1.25 | $5.00 | 고성능 |
| Gemini 2.5 Pro | $0.60 | $2.40 | 균형형 |
| Gemini 3.0 Ultra | $5.00 | $20.00 | 최고성능 |

**비유로 이해하기:**
```
[자동차 선택하기]

경차 (Gemini Flash)
- 저렴함: $20,000
- 연비: 적음
- 용도: 일상 통근
→ 대량 서비스에 적합

중형차 (Gemini Pro)
- 중간: $40,000
- 연비: 중간
- 용도: 비즈니스
→ 균형이 필요할 때

슈퍼카 (Gemini Ultra)
- 비쌈: $200,000
- 연비: 많음
- 용도: 레이싱
→ 최고 성능이 필요할 때
```

### 2.4. 무료 vs 유료 모델

**비교:**

| 특징 | 무료 모델 (Ollama) | 유료 모델 (Gemini) |
|------|-------------------|-------------------|
| 비용 | 무료 | 유료 |
| 성능 | 중간 | 높음 |
| 속도 | 느림 | 빠름 |
| 관리 | 직접 설치 | API 사용 |
| 확장성 | 제한적 | 높음 |

**선택 가이드:**
```
[무료 모델이 좋은 경우]
- 테스트 환경
- 소규모 서비스
- 예산 제한 있음
- 직접 관리 가능

[유료 모델이 좋은 경우]
- 대규모 서비스
- 빠른 응답 필요
- 높은 성능 필요
- 운영 편의성 중요
```

---

## 3. 비용 최적화 전략

### 3.1. Top-K 최적화

검색 결과 수를 줄이면 토큰을 절약할 수 있습니다.

**비교:**
```
[Top-K = 100]
컨텍스트 토큰: 10,000토큰
비용: $1.00
응답 시간: 5초
→ 너무 많음

[Top-K = 10]
컨텍스트 토큰: 1,000토큰
비용: $0.10
응답 시간: 2초
→ 적절

[Top-K = 3]
컨텍스트 토큰: 300토큰
비용: $0.03
응답 시간: 1초
→ 정보 부족 가능
```

### 3.2. 컨텍스트 요약

도서 정보를 요약하면 토큰을 줄일 수 있습니다.

**전처리 전:**
```
[원본]
이 책은 자바의 기초부터 시작해서 객체 지향 프로그래밍의 핵심 개념을
상세하게 다룹니다. 클래스와 객체, 상속과 다형성, 인터페이스와 추상
클래스, 예외 처리, 컬렉션 프레임워크, 스트림 API 등 다양한 주제를
포함하고 있습니다...
→ 500자, 150토큰
```

**전처리 후:**
```
[요약]
자바의 기초부터 객체 지향까지 다루는 입문서입니다.
→ 30자, 10토큰

토큰 절약: 140토큰 → 10토큰 (93% 절약)
```

### 3.3. 캐싱 활용

동일한 질문에 대해서는 AI를 다시 호출하지 않습니다.

**비교:**
```
[캐싱 없음]
질문: "자바 책 추천해줘"
1번째 요청: AI 호출 ($0.10)
2번째 요청: AI 호출 ($0.10)
3번째 요청: AI 호출 ($0.10)
총비용: $0.30

[캐싱 있음]
질문: "자바 책 추천해줘"
1번째 요청: AI 호출 ($0.10) → 캐시 저장
2번째 요청: 캐시 사용 ($0.00)
3번째 요청: 캐시 사용 ($0.00)
총비용: $0.10
```

---

## 4. 성능 모니터링

### 4.1. 측정 지표

각 단계별로 소요 시간을 측정합니다.

**구현 예시:**
```java
long startTime = System.currentTimeMillis();

// 1. 검색
List<Book> books = searchBooks(question);
long searchTime = System.currentTimeMillis() - startTime;

// 2. 컨텍스트 구축
String context = buildContext(books);
long contextTime = System.currentTimeMillis() - startTime - searchTime;

// 3. AI 호출
String response = callAI(prompt);
long aiTime = System.currentTimeMillis() - startTime - searchTime - contextTime;

log.info("검색: {}ms, 컨텍스트: {}ms, AI: {}ms",
        searchTime, contextTime, aiTime);
```

**출력 예시:**
```
검색: 250ms, 컨텍스트: 50ms, AI: 1800ms
총: 2100ms (2.1초)
```

### 4.2. 성능 목표

**목표 설정:**
```
[검색]
목표: 500ms 이하
현재: 250ms

[임베딩]
목표: 300ms 이하
현재: 200ms

[AI 생성]
목표: 2000ms 이하
현재: 1800ms

[전체]
목표: 3000ms 이하
현재: 2250ms
```

---

## 5. 비용 계산 실습

### 5.1. 월간 비용 계산

**시나리오:**
- 일일 사용자: 1,000명
- 1인당 평균 요청: 2회
- 요청당 평균 토큰: 입력 1,000 + 출력 500 = 1,500토큰
- Gemini 2.0 Flash 가격: 입력 $0.10/1M, 출력 $0.40/1M

**계산:**
```
1일 토큰:
1,000명 × 2회 × 1,500토큰 = 3,000,000토큰

1일 비용:
입력: 2,000,000 × $0.10 / 1,000,000 = $0.20
출력: 1,000,000 × $0.40 / 1,000,000 = $0.40
총: $0.60

1월 비용:
$0.60 × 30일 = $18.00

1년 비용:
$0.60 × 365일 = $219.00
```

### 5.2. 최적화 효과

**최적화 전:**
```
1일 토큰: 3,000,000토큰
1일 비용: $0.60
1월 비용: $18.00
```

**최적화 후 (50% 감축):**
```
1일 토큰: 1,500,000토큰
1일 비용: $0.30
1월 비용: $9.00

절감: $9.00/월 ✅
```

---

## 6. 실습 미션

### 미션 1: 토큰 수 계산

```java
@Test
void testTokenCalculation() {
    String text = "안녕하세요, 자바의 정석을 추천합니다";

    // 대략적인 토큰 수 계산
    // 한글: 1글자 ≈ 0.5토큰
    // 영어: 1단어 ≈ 0.7토큰
    int estimatedTokens = text.length() / 2;

    System.out.println("텍스트: " + text);
    System.out.println("예상 토큰: " + estimatedTokens);

    assertTrue(estimatedTokens > 0);
}
```

### 미션 2: 비용 계산

```java
@Test
void testCostCalculation() {
    // 입력 1,000토큰, 출력 500토큰
    int inputTokens = 1000;
    int outputTokens = 500;

    // Gemini 2.0 Flash 가격
    double inputPrice = 0.10 / 1_000_000;
    double outputPrice = 0.40 / 1_000_000;

    double cost = inputTokens * inputPrice + outputTokens * outputPrice;

    System.out.println("입력 토큰: " + inputTokens);
    System.out.println("출력 토큰: " + outputTokens);
    System.out.printf("비용: $%.4f\n", cost);

    assertEquals(0.0003, cost, 0.0001);
}
```

### 미션 3: 성능 측정

```java
@Test
void testPerformanceMeasurement() {
    long startTime = System.currentTimeMillis();

    // RAG 추천 실행
    List<BookAiRecommendationResponse> recommendations =
            bookRagService.recommendBooks("자바 책");

    long endTime = System.currentTimeMillis();
    long duration = endTime - startTime;

    System.out.println("응답 시간: " + duration + "ms");

    // 성능 목표 확인
    assertTrue(duration < 5000, "5초 이내여야 함");
}
```

---

## 7. 학습 체크리스트

다음 내용을 이해했는지 확인해 보세요:

- [ ] 응답 지연이 무엇인지 안다
- [ ] 토큰과 비용의 관계를 이해한다
- [ ] 모델별 가격 차이를 안다
- [ ] Top-K 최적화 필요성을 이해한다
- [ ] 컨텍스트 요약으로 비용 절감 가능하다
- [ ] 캐싱으로 비용 절감 가능하다
- [ ] 월간 비용을 계산할 수 있다
- [ ] 성능 모니터링을 할 수 있다

---

## 8. 다음 단계

다음 문서에서는 **Top-K와 컨텍스트 최적화**를 배웁니다:
- 적절한 Top-K 값 설정
- 컨텍스트 크기 최적화
- 검색 품질과 비용의 균형

[다음: 02. Top-K와 컨텍스트 최적화 →](02.topk-and-context-optimization.md)

---

## ❓ FAQ (자주 묻는 질문)

### Q1: 어떤 모델을 선택해야 하나요?

**A:** 사용량과 용도에 따라 다릅니다.

| 상황 | 추천 모델 | 이유 |
|------|-----------|------|
| 개발/테스트 | gemini-2.0-flash | 빠르고 저렴함 |
| 상용 서비스 | gemini-2.0-flash | 빠른 응답 시간 |
| 고품질 답변 필요 | gemini-2.5-pro | 더 정확한 답변 |

**비용 비교 (1M 토큰 기준):**
- Flash: $0.10 (입력) / $0.40 (출력)
- Pro: $1.25 (입력) / $2.50 (출력)

### Q2: 응답 시간이 너무 깁니다. 어떻게 개선하나요?

**A:** 병목을 찾아서 해결해야 합니다.

1. **검색이 느린 경우:**
   - 인덱스 확인
   - 쿼리 최적화
   - 임베딩 캐싱

2. **AI 호출이 느린 경우:**
   - 더 빠른 모델 사용 (Flash)
   - 컨텍스트 크기 줄이기
   - Top-K 줄이기

3. **네트워크 지연:**
   - CDN 활용
   - API 엔드포인트 확인

### Q3: 비용이 너무 많이 나옵니다. 어떻게 줄이나요?

**A:** 다음 방법들을 순서대로 시도해 보세요.

1. **캐싱:** 동일 질문 재사용
2. **Top-K 줄이기:** 10 → 5
3. **컨텍스트 요약:** 500자 → 200자
4. **더 저렴한 모델:** Pro → Flash
5. **오프라인 배치:** 실시간이 필요 없는 경우

### Q4: 캐시는 얼마나 유지해야 하나요?

**A:** 도서 정보는 1시간~1일이 적당합니다.

| 데이터 종류 | 캐시 시간 | 이유 |
|------------|-----------|------|
| 도서 검색 결과 | 1시간 | 도서 정보가 자주 변하지 않음 |
| 리뷰 요약 | 1일 | 리뷰가 잘 안 생김 |
| 사용자 질문 | 10분 | 같은 질문을 다시 할 가능성 |

### Q5: 토큰을 정확히 계산하려면?

**A:** TikToken 라이브러리를 사용하세요.

```java
// 대략적인 계산 (실제와 다를 수 있음)
한글: 1글자 ≈ 0.5토큰
영어: 1단어 ≈ 0.7토큰

// 정확한 계산 (라이브러리 사용)
// spring-ai-openai의 TokenUtil 활용
```

---

## 🔧 트러블슈팅

### 문제 1: AI 응답이 잘리지 않습니다

**증상:** 응답 중간에 멈춥니다.

**원인:** 출력 토큰 한도 초과

**해결:**
1. `max_tokens` 설정 확인
2. 프롬프트에 "간결하게 답변하세요" 추가
3. 출력 토큰 제한 설정

### 문제 2: 비용이 예상보다 훨씬 많이 나옵니다

**증상:** 계산된 비용의 2배 이상 나옵니다.

**원인:**
- 토큰 계산 실수
- 캐시가 작동하지 않음
- 무한 루프로 AI 호출

**해결:**
1. 실제 토큰 사용량 확인 (로그 출력)
2. 캐시 동작 확인
3. 프로파일링으로 호출 횟수 확인

### 문제 3: 응답 시간이 갑자기 느려졌습니다

**증상:** 평소 2초였는데 10초 이상 걸립니다.

**원인:**
- API 서버 과부하
- 네트워크 문제
- 임베딩 생성 중복 호출

**해결:**
1. 임베딩 캐싱 확인
2. 재시도 로직 추가
3. API 상태 확인

### 문제 4: "Rate limit exceeded" 에러

**증상:** API 호출 한도 초과 에러

**원인:** 무료 요금제 한도 초과

**해결:**
1. 사용량 확인
2. 유료 요금제로 업그레이드
3. Rate limiting 적용

---

## 📖 참고자료

### 공식 문서
- [Google Gemini Pricing](https://ai.google.dev/pricing)
- [Spring AI Documentation](https://docs.spring.io/spring-ai/reference/)
