# 04. 의미 검색: 자연어 기반 벡터 검색 도입

Week 2의 마지막 단계로, 생성된 임베딩(Embedding)을 활용하여 사용자의 질문 의도를 파악하고 가장 유사한 도서를 찾아내는 **벡터 검색(Vector Search)** 기능을 구현합니다.

## 1. 개요

이제 '키워드'가 아닌 '의미'로 도서를 찾을 수 있습니다. 사용자가 "마음이 편안해지는 책 추천해줘"라고 검색하면, 시스템은 이 문장을 벡터로 변환하고 DB에 저장된 도서 벡터들과의 거리를 계산하여 가장 가까운(유사한) 도서들을 반환합니다. 이것이 바로 **의미 기반 검색(Semantic Search)** 의 핵심입니다.

## 2. 주요 개념

### 2.1. 벡터 검색 (Vector Search)
두 벡터 사이의 거리를 계산하여 '유사도'를 측정하는 검색 방식입니다.

#### 1) 코사인 유사도 (Cosine Similarity)
벡터 사이의 각도를 측정하여 방향이 얼마나 일치하는지 계산합니다. 1에 가까울수록 유사합니다.

*   **수식**:
    $$\text{similarity} = \cos(\theta) = \frac{A \cdot B}{\|A\| \|B\|} = \frac{\sum_{i=1}^{n} A_i B_i}{\sqrt{\sum_{i=1}^{n} A_i^2} \sqrt{\sum_{i=1}^{n} B_i^2}}$$
*   **수식 설명**:
    *   $A \cdot B$: 두 벡터의 내적 (각 요소의 곱의 합)
    *   $\|A\|, \|B\|$: 각 벡터의 크기(L2 노름)
    *   두 벡터의 방향이 같으면 1, 90도이면 0, 반대 방향이면 -1을 가집니다.
*   **언제 사용하나요?**:
    *   **문장의 의미 비교**: 단어의 빈도나 문장의 길이에 상관없이 '주제'나 '의미'의 방향성이 얼마나 유사한지 측정할 때 유리합니다.
    *   텍스트 데이터나 추천 시스템에서 가장 널리 사용됩니다.

#### 2) L2 거리 (Euclidean Distance)
두 점 사이의 직선 거리를 측정합니다. 0에 가까울수록 유사합니다.

*   **수식**:
    $$d(A, B) = \sqrt{\sum_{i=1}^{n} (A_i - B_i)^2}$$
*   **수식 설명**:
    *   $A_i, B_i$: 두 벡터의 각 차원 값
    *   피타고라스 정리를 $n$차원으로 확장한 것과 같으며, 두 벡터 끝점 사이의 최단 직선 거리를 구합니다.
*   **언제 사용하나요?**:
    *   **데이터의 크기가 중요할 때**: 벡터의 방향뿐만 아니라 요소의 절대적인 수치 차이가 중요할 때 사용합니다.
    *   이미지 처리나 일반적인 클러스터링 알고리즘(K-means 등)에서 기본 거리 지표로 자주 사용됩니다.

### 2.2. pgvector 연산자
PostgreSQL에서 벡터 검색을 수행할 때 사용하는 특수 연산자입니다.
- `<=>`: 코사인 거리 (1 - 코사인 유사도)
- `<->`: L2 거리
- `<#>`: 내적 (Inner Product)

## 3. 구현 가이드 (Step-by-Step)

### 3.1. 검색어의 벡터화
사용자가 입력한 검색어(자연어)를 도서 데이터와 동일한 AI 모델을 사용하여 벡터로 변환합니다.

### 3.2. 벡터 검색 쿼리 작성 (SQL)
`pgvector` 연산자를 사용하여 가장 유사한 도서 TOP 5를 조회합니다.
```sql
SELECT title, book_content, 1 - (embedding <=> '[사용자_검색어_벡터]') AS similarity
FROM books
ORDER BY embedding <=> '[사용자_검색어_벡터]'
LIMIT 5;
```

### 3.3. QueryDSL 연동
하이버네이트에서 `pgvector` 연산자를 인식할 수 있도록 `FunctionContributor`에 벡터 유사도 계산을 위한 `vector_cosine_similarity` 함수를 등록하여 사용합니다.

```java
// PostgreSQLFunctionContributor.java
functionContributions.getFunctionRegistry()
        .registerPattern("vector_cosine_similarity",
                "(1.0 - (embedding <=> cast(?1 as vector)))",
                functionContributions.getTypeConfiguration().getBasicTypeRegistry().resolve(StandardBasicTypes.DOUBLE));
```

QueryDSL에서는 등록된 커스텀 함수를 호출하여 유사도 점수를 계산하고 정렬합니다.

```java
// BookRepositoryImpl.java
NumberTemplate<Double> similarityTemplate = Expressions.numberTemplate(Double.class, "function('vector_cosine_similarity', {0})", vectorString);

List<BookSearchResponse> results = queryFactory
        .from(book)
        .select(Projections.constructor(BookSearchResponse.class, ..., similarityTemplate))
        .where(Expressions.booleanTemplate("embedding is not null"))
        .orderBy(similarityTemplate.desc())
        .fetch();
```

### 3.4. UI 결과 노출
기존 키워드 검색 결과 옆에 '유사도 점수'를 표시하여 AI가 얼마나 확신을 가지고 추천했는지 보여줍니다.

## 4. 학습 포인트

*   **의미적 유사도 체감**: 키워드가 하나도 겹치지 않아도 뜻이 통하는 책이 검색되는 과정을 직접 확인합니다.
*   **거리 연산의 이해**: 수학적인 '거리' 개념이 어떻게 IT 서비스의 '유사도'로 치환되는지 학습합니다.
*   **전통적 검색과의 조화**: 키워드 검색(정확도)과 벡터 검색(유연성)을 어떻게 상호 보완적으로 사용할 수 있을지 고민해 봅니다.

## 5. 심화 학습 (Study Topics)

숫자로 뜻을 찾는 벡터 검색에 대해 쉽게 알아봅시다.

### 5.1. 숨은 그림 찾기 (Vector Search)
키워드 검색이 "사과"라는 글자가 있는지 찾는 것이라면, 벡터 검색은 "사과처럼 생기고 빨간 것"을 찾는 것과 같습니다.
- **비유**: 친구에게 "키 큰 사람 찾아봐"라고 하면 친구는 머릿속에 '키 큰 사람'의 이미지를 떠올리고 눈앞의 사람들과 대조해 보겠죠? 벡터 검색도 AI가 가진 '의미 이미지(벡터)'를 대조하는 과정입니다.

### 5.2. 1등부터 5등까지 (Ranking)
벡터 검색은 항상 '가장 가까운 것'을 순서대로 알려줍니다. 결과가 0건인 경우는 거의 없습니다.
- **비유**: 달리기 경주에서 결승선에 가장 먼저 들어온 사람부터 순위를 매기는 것과 같습니다. 키워드 검색은 "10초 안에 들어온 사람!"이라고 딱 잘라 말하는 것(Filter)이라면, 벡터 검색은 "누가 제일 빨리 들어왔니?"라고 묻는 것(Rank)입니다.

## 6. 참고 링크

*   [pgvector Indexing (IVFFlat, HNSW)](https://github.com/pgvector/pgvector?tab=readme-ov-file#indexing)
*   [What is Cosine Similarity?](https://en.wikipedia.org/wiki/Cosine_similarity)
*   [Spring AI Vector Database Reference](https://docs.spring.io/spring-ai/reference/api/vectordbs.html)
