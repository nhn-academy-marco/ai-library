# 01. 한계 체감: 키워드 검색의 품질 문제 분석

Week 2의 첫 번째 단계로, 지금까지 구현한 전통적인 검색 방식(LIKE, 전문 검색)이 가진 실무적인 한계를 직접 경험하고, 왜 AI 기반의 벡터 검색(Vector Search)이 필요한지 그 배경을 학습합니다.

## 1. 개요

우리는 Week 1에서 RDBMS(PostgreSQL)를 활용하여 키워드 기반의 검색 시스템을 구축했습니다. 하지만 실제 서비스에서는 사용자가 정확한 키워드를 입력하지 않거나, 단어의 의미를 바탕으로 검색하고 싶어 하는 경우가 많습니다. 본 문서에서는 전통적인 검색 방식이 부딪히는 '품질의 벽'을 분석합니다.

## 2. 전통적 검색의 한계 (The Limits of Keyword Matching)

### 2.1. 동의어 및 유의어 처리 불가 (Synonym Problem)
키워드 매칭은 글자 그대로 일치해야 결과를 찾아냅니다.
- **예시**: 사용자가 '컴퓨터 구조'를 검색했을 때, 책 제목이나 내용에 'Computer Architecture'라고만 적혀 있다면 결과에 노출되지 않습니다.
- **이유**: 시스템은 '컴퓨터'와 'Computer'가 같은 의미라는 것을 알지 못합니다.

### 2.2. 오타 및 형태 변화에 취약 (Typo & Inflection)
- **예시**: '자바'를 '좌바'로 입력하거나, '프로그래밍'을 '프로그램'으로 입력했을 때 매칭율이 급격히 떨어집니다.
- **이유**: 글자 패턴(Pattern)에 의존하기 때문에 약간의 변형만으로도 검색 결과에서 제외됩니다.

### 2.3. 문맥 및 의미 파악 불가 (Semantic Gap)
- **예시**: '가벼운 노트북'을 검색했을 때, 단순히 '가볍다'와 '노트북'이라는 단어가 포함된 모든 문서를 보여줍니다. 하지만 사용자가 원하는 것은 '휴대성이 좋은 노트북'이라는 **의도**입니다.
- **이유**: 단어 간의 관계나 문장의 맥락(Context)을 이해하지 못하고 개별 단어의 존재 여부만 판단합니다.

### 2.4. 검색 결과의 경직성
- '전부 아니면 전무(All or Nothing)' 방식입니다. 키워드가 없으면 결과가 0건이 되고, 이는 곧 사용자 이탈로 이어집니다.

## 3. 전문 검색(Full Text Search)도 해결하지 못한 것

Week 1에서 배운 전문 검색(Full Text Search)은 성능은 개선했지만, **'의미(Semantic)'**의 문제는 해결하지 못했습니다.
- 역색인(Inverted Index)은 여전히 '단어'를 기준으로 작동합니다.
- 토큰화(Tokenization)를 아무리 잘해도 단어 자체의 의미적 유사성을 계산하지는 않습니다.

## 4. 해결책: 벡터 검색(Vector Search)의 등장

이러한 한계를 극복하기 위해 데이터를 숫자의 나열인 **벡터(Vector)** 로 변환하여 저장하고 검색하는 방식이 도입되었습니다.
- **임베딩(Embedding)**: 단어나 문장을 다차원 공간상의 좌표(Vector)로 변환합니다.
- **의미적 유사도**: '사과'와 '배'는 공간상에서 가깝게 위치하게 됩니다. 이를 통해 키워드가 일치하지 않아도 의미가 비슷한 결과를 찾아낼 수 있습니다.

## 5. 학습 포인트

* **검색 품질의 정의**: 단순히 '빨리' 찾는 것보다 '정확하게(사용자의 의도에 맞게)' 찾는 것이 왜 중요한지 이해합니다.
* **키워드 검색의 기술적 부채**: 불용어(Stopwords) 처리, 동의어 사전 관리 등 전통적 방식에서 품질을 높이기 위해 들어가는 운영 공수를 체감합니다.
* **AI 도입의 명분**: AI(LLM, Embedding)가 단순히 유행이 아니라, 기존 검색 시스템의 고질적인 문제를 해결하기 위한 실무적인 도구임을 인식합니다.

## 6. 심화 학습 (Study Topics)

대학생 여러분의 이해를 돕기 위해, 검색 시스템의 품질을 측정하고 개선하는 핵심 개념들을 쉬운 비유와 함께 소개합니다.

### 6.1. 검색이 얼마나 정확한가? (Precision vs Recall)
검색 엔진이 얼마나 일을 잘했는지 평가하는 두 가지 잣대입니다.
- **정밀도 (Precision)**: "검색 결과 중에 진짜 쓸모 있는 게 얼마나 있는가?" (품질의 문제)
    - 예: 10개를 검색했는데 그중 8개가 내가 찾던 책이라면 정밀도는 80%입니다.
- **재현율 (Recall)**: "전체 데이터 중 내가 찾던 걸 얼마나 많이 찾아냈는가?" (누락의 문제)
    - 예: 도서관에 내가 찾는 주제의 책이 10권 있는데, 5권만 찾아냈다면 재현율은 50%입니다.
- **비유**: 그물을 던졌을 때, **물고기만 골라 잡는 것**이 정밀도라면 **바다 속 물고기를 한 마리도 안 놓치고 다 잡는 것**이 재현율입니다.

### 6.2. 검색 결과가 얼마나 관련 있는가? (Search Relevance)
단순히 키워드가 포함되었다고 다 같은 순서로 보여주지 않습니다.
- **BM25 알고리즘**: 단어가 문서에 얼마나 자주 나오는지, 문서가 얼마나 긴지 등을 계산해 점수를 매기는 가장 대표적인 랭킹 알고리즘입니다.
- **비유**: 시험 문제에서 '중요한 단어'를 많이 쓴 답안지에 높은 점수를 주는 것과 비슷합니다.

### 6.3. 키워드를 넘어 의미로 (Semantic Search)
키워드가 똑같지 않아도 '뜻'이 통하면 찾아주는 기술입니다.
- **벡터(Vector)**: 단어의 의미를 숫자의 나열(좌표)로 표현한 것입니다. '왕'과 '왕비'는 숫자상으로 아주 가까운 곳에 위치하게 됩니다.
- **비유**: 외국인과 대화할 때 단어는 틀려도 몸짓 발짓으로 '의미'가 통하는 것과 같습니다.

## 7. 참고 링크

학생들의 학습에 도움이 되는 신뢰할 수 있는 최신 자료들입니다.

- [Elasticsearch - Search Relevance란 무엇인가?](https://www.elastic.co/what-is/search-relevance) (검색 관련성의 기초 개념)
- [Elasticsearch - Semantic Search의 이해](https://www.elastic.co/what-is/semantic-search) (의미 기반 검색의 원리)
- [Pinecone - Semantic Search 학습 가이드](https://www.pinecone.io/learn/semantic-search/) (벡터 검색과 임베딩에 대한 쉬운 설명)
- [Wikipedia - Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall) (정밀도와 재현율의 정의)
