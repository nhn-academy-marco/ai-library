# 01. 데이터 적재: 공공 도서 CSV Batch Load

Week 1의 첫 번째 단계로, 외부 공공 도서 데이터를 시스템의 데이터베이스(PostgreSQL)에 배치(Batch) 방식으로 적재하는 과정을 설명합니다.

## 1. 개요

AI 시스템의 성능은 양질의 데이터에서 시작됩니다. 본 단계에서는 제공된 공공 도서 CSV 데이터를 읽어와서 DB에 저장하는 초기 데이터 구축 프로세스(Batch Load)를 구현합니다. 효율적인 처리를 위해 이벤트 기반 아키텍처(EDA)와 스프링의 트랜잭션(Transaction) 관리를 활용합니다.

## 2. 주요 개념 및 아키텍처

학생들은 단순히 코드를 복사하기보다 다음의 핵심 개념들이 왜 이 구조에서 사용되었는지 이해해야 합니다.

### 2.1. 이벤트 기반 아키텍처 (Event-Driven Architecture)
데이터 파싱(Parsing)과 저장(Service) 로직이 서로를 직접 알지 못하도록 분리되어 있습니다.
- **장점**: 파서가 CSV뿐만 아니라 XML, API 등으로 확장되어도 저장 로직은 수정할 필요가 없습니다.
- **핵심 요소**: `ApplicationEventPublisher` (발행), `@EventListener` (구독).

### 2.2. 벌크 적재 및 트랜잭션 (Bulk Insert & Transaction)
대량의 데이터를 하나씩 DB에 저장하는 것은 매우 느립니다.
- **Batch Size**: 1,000개 단위로 모아서 한 번에 저장(`saveAll`)하여 네트워크 왕복(Network Round-trip) 횟수를 줄입니다.
- **트랜잭션 관리**: `@Transactional`을 통해 배치 단위의 원자성(Atomicity)을 보장합니다.

### 2.3. 상수화 (Constants) 및 로깅 (Logging)
- **상수화**: CSV 헤더명 등 의미 있는 문자열은 매직 스트링(Magic String)을 피하기 위해 `public static final` 상수로 정의합니다.
- **로깅**: `@Slf4j`를 활용하여 `DEBUG`, `INFO`, `ERROR` 레벨별로 적절한 정보를 기록합니다.

## 3. 구현 가이드 (Step-by-Step)

### 3.1. 데이터 모델 설계
CSV 레코드와 매핑되는 `BookRawData`(DTO)와 실제 DB에 저장될 `Book`(Entity)을 만듭니다.

**BookRawData.java (DTO)**
```java
@Data
public class BookRawData {
    private Long id;
    private String isbn;
    private String title;
    private String authorName;
    private String publisherName;
    // ... CSV 헤더에 대응하는 필드
}
```

### 3.2. 파싱 로직 구현 (CSV Parser)
`Apache Commons CSV` 라이브러리를 사용하여 파일을 읽고, 각 레코드마다 이벤트를 발행합니다.

**CsvBookParser.java**
```java
@Component
@RequiredArgsConstructor
public class CsvBookParser implements BookParser {
    private final ApplicationEventPublisher eventPublisher;

    public void parse() {
        // ... 리더 및 파서 설정
        for (CSVRecord record : parser) {
            BookRawData book = new BookRawData();
            book.setTitle(record.get("TITLE_NM"));
            // ... 데이터 매핑
            
            // 데이터 한 건당 이벤트 발행
            eventPublisher.publishEvent(new BookParsedEvent(book));
        }
        // 파싱 완료 이벤트 발행
        eventPublisher.publishEvent(new BookParsingCompleteEvent());
    }
}
```

### 3.3. 이벤트 리스너 작성
발행된 이벤트를 리스트(버퍼)에 담고, 파싱 완료 이벤트가 오면 실제 저장 서비스를 호출합니다.

**BookParsingEventListener.java**
```java
@Component
@RequiredArgsConstructor
public class BookParsingEventListener {
    private final List<BookRawData> buffer = new ArrayList<>();
    private final BookBatchService batchService;

    @EventListener
    public void onBookParsed(BookParsedEvent event) {
        buffer.add(event.bookRawData());
    }

    @EventListener
    public void onParsingCompleted(BookParsingCompleteEvent event) {
        batchService.initializeBooks(buffer, batchSize);
    }
}
```

### 3.4. 배치 저장 서비스 구현
전달받은 리스트를 `batchSize` 단위로 나누어 `saveAll()`을 호출합니다.

**BookBatchService.java**
```java
@Service
@Transactional
public class BookBatchService {
    public void initializeBooks(List<BookRawData> data, int batchSize) {
        // 기존 데이터 삭제 (필요 시)
        // 리스트를 batchSize 단위로 분할하여 saveAll 호출
        for (int i = 0; i < data.size(); i += batchSize) {
            List<Book> subList = // ... Book 엔티티로 변환
            repository.saveAll(subList);
        }
    }
}
```

## 4. 전체 흐름 (Sequence)

1. **애플리케이션 시작**: `ApplicationReadyEvent` 발생 시 `BookParsingEventListener`가 활성화됩니다.
2. **설정 확인**: `init.enable` 설정이 `true`인 경우에만 파싱을 시작합니다.
3. **CSV 파싱**: `CsvBookParser`가 파일을 읽으며 매 레코드마다 `BookParsedEvent`를 발행합니다.
4. **데이터 수집(Buffer)**: 리스너가 발행된 이벤트를 받아 내부 `buffer` (List)에 저장합니다.
5. **파싱 종료**: 모든 레코드를 읽으면 `BookParsingComplateEvent`가 발행됩니다.
6. **DB 적재**: 리스너가 `BookBatchService.initializeBooks()`를 호출합니다.
   * 기존 데이터 삭제
   * 설정된 `batchSize` 단위로 나누어 DB 저장 (`saveAll`)

## 5. 설정 (application.properties)

배치 작업은 다음 설정을 통해 제어할 수 있습니다.

```properties
init.enable=true
init.book_file=data/init/BOOK_DB_202112.csv
init.batch_size=1000
```

* `init.enable`: 배치 실행 여부 (개발 초기 1회 실행 후 false 권장)
* `init.book_file`: 적재할 CSV 파일 경로
* `init.batch_size`: 한 번의 트랜잭션으로 처리할 데이터 개수

## 6. 학습 포인트

* **AI를 위한 원천 데이터(Corpus) 구축**: AI 모델의 학습이나 RAG의 기반이 되는 깨끗한 텍스트 데이터(Corpus)를 확보하는 과정의 중요성을 이해합니다.
* **이벤트 기반 아키텍처(EDA)**: `ApplicationEventPublisher`를 활용해 파싱 로직과 저장 로직을 분리하여 시스템의 확장성과 유지보수성을 높입니다.
* **배치 처리 성능 최적화**: 대량의 데이터를 하나씩 저장하지 않고 `saveAll`과 `batch-size` 설정을 통해 DB I/O 성능을 극대화하는 방법을 익힙니다.
* **데이터 품질 관리**: CSV 데이터의 누락, 형식 오류 등을 처리하는 방어적인 코딩 기법을 통해 데이터 신뢰성을 확보합니다.

## 7. 깊이 공부하기 (Study Topics)

처음 백엔드를 접하는 학생들을 위해 핵심 개념을 쉽게 풀어서 소개합니다.

### 7.1. 이벤트(Event)로 대화하기
프로그램 내부에서 "나 이거 끝냈어!"라고 소리치면(발행), 관심 있는 다른 기능들이 "그래? 그럼 난 이걸 할게"라고 반응하는 방식입니다.
- **비유**: 식당에서 벨을 누르면(이벤트 발행), 주방에서 음식을 준비하기 시작하는 것과 같습니다. 서로 직접 대화하지 않아도 벨소리 하나로 각자의 할 일을 할 수 있습니다.

### 7.2. 한 번에 모아서 처리하기 (Batch Insert)
데이터를 하나씩 DB에 저장하는 대신, 박스에 가득 채워서 한 번에 트럭으로 옮기는 것과 같습니다.
- **비유**: 편지 100통을 보낼 때, 한 통 쓸 때마다 우체국에 가는 대신 100통을 다 써서 한 번에 우체국에 가져가는 것이 훨씬 효율적입니다.

### 7.3. 트랜잭션(Transaction) - 전부 성공 아니면 실패
데이터를 저장하다가 중간에 에러가 나면, 어설프게 저장된 데이터를 모두 취소하고 처음 상태로 되돌리는 안전장치입니다.
- **비유**: 은행 이체를 할 때 내 통장에서 돈은 빠져나갔는데 상대방 통장에 안 들어왔다면? 이 전체 과정을 취소하고 내 돈을 돌려받아야 합니다.

## 8. 참고 링크

- [Spring Framework - Application Events](https://docs.spring.io/spring-framework/reference/core/beans/context-introduction.html#context-introduction-event)
- [Apache Commons CSV User Guide](https://commons.apache.org/proper/commons-csv/user-guide.html)
- [Baeldung - Spring Data JPA saveAll() vs save()](https://www.baeldung.com/spring-data-save-saveall)
- [PostgreSQL COPY Command](https://www.postgresql.org/docs/current/sql-copy.html)
