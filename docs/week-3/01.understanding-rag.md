# 01. RAG의 이해: AI가 답변을 생성하는 원리

Week 3의 첫 번째 단계로, LLM(Large Language Model)의 한계를 극복하고 신뢰할 수 있는 답변을 생성하기 위한 핵심 기술인 **RAG(Retrieval-Augmented Generation)** 의 개념과 필요성을 학습합니다.

## 1. 개요

단순히 AI에게 질문을 던지면 AI는 자신의 지식만으로 답변을 하려 합니다. 하지만 AI가 학습하지 않은 최신 데이터나 우리 시스템에만 있는 특정 도서 정보에 대해서는 잘못된 답변을 내놓을 수 있는데, 이를 **환각(Hallucination)** 현상이라고 합니다. RAG는 이 문제를 해결하기 위해 검색(Retrieval)과 생성(Generation)을 결합한 방식입니다.

## 2. 주요 개념

### 2.1. Hallucination (환각 현상)
AI가 그럴듯해 보이지만 사실과는 다른 정보를 생성하는 현상입니다.
- **원인**: 학습 데이터의 부재, 지식의 유효기간 만료, 복잡한 논리 구조에서의 오류 등.
- **도서 검색에서의 예시**: 실제로 존재하지 않는 도서 제목을 지어내거나, 저자를 잘못 매칭하는 경우.

### 2.2. RAG (Retrieval-Augmented Generation)
'검색 증강 생성'이라고 하며, 답변을 생성하기 전에 관련된 신뢰할 수 있는 정보를 먼저 찾아서(Retrieval) 그 정보를 바탕으로 답변을 생성하도록(Generation) 하는 기술입니다.
- **작동 원리**: 질문 → **관련 문서 검색** → 질문 + 검색된 문서 제공 → AI 답변 생성.
- **비유**: 시험을 볼 때 암기한 내용으로만 답하는 것이 아니라, 관련 참고서를 옆에 펼쳐두고(Open-book) 답을 찾는 것과 같습니다.

## 3. RAG 구현 흐름

본 프로젝트에서 구현된 RAG 시스템은 단순 검색을 넘어 **하이브리드 검색(Hybrid Search)**을 기반으로 더욱 정교한 컨텍스트를 제공합니다.

1.  **사용자 질문(Query) 수신**: 사용자가 검색창에 궁금한 내용을 입력하고 "AI 도서 추천 (RAG)" 방식을 선택합니다.
2.  **임베딩(Embedding) 생성**: 입력된 검색 키워드를 AI 모델을 통해 수치 벡터로 변환합니다.
3.  **하이브리드 검색(Hybrid Search) 수행**:
    *   **키워드 검색(Keyword Search)**: 제목, 저자 등 텍스트 매칭 기반 검색.
    *   **벡터 검색(Vector Search)**: 의미적 유사도 기반 검색.
    *   **RRF(Reciprocal Rank Fusion)**: 두 검색 결과를 결합하여 최적의 상위 도서 리스트를 추출합니다.
4.  **컨텍스트(Context) 구축**: 검색된 상위 도서들의 상세 정보(제목, 저자, 출판일, 내용 등)를 AI가 이해하기 쉬운 Markdown 형태의 텍스트로 재구성합니다.
5.  **프롬프트(Prompt) 생성**: 사서 페르소나, 규칙, 출력 형식(JSON)이 포함된 템플릿에 사용자 질문과 컨텍스트를 결합합니다.
6.  **LLM(Ollama/Gemini) 호출**: 구성된 프롬프트를 AI 모델에게 전달하여 분석 및 추천 결과 생성을 요청합니다.
7.  **응답 역직렬화 및 표시**: AI가 반환한 JSON 데이터를 Java DTO로 변환하여 화면에 추천 도서 리스트와 추천 사유를 깔끔하게 출력합니다.

## 4. 데이터 지표의 이해

RAG 시스템에서는 검색 결과의 신뢰도를 높이기 위해 다음과 같은 지표를 활용합니다.

*   **AI 추천 % (Relevance)**: AI 모델이 사용자의 질문(Query)과 해당 도서의 관련성을 분석하여 부여한 점수입니다. (0~100%)
*   **일치율 (Similarity)**: 벡터 임베딩을 통해 계산된 수치적 유사도입니다. 검색어와 도서의 의미가 얼마나 가까운지를 나타냅니다.
*   **RRF (Reciprocal Rank Fusion)**: 전통적인 키워드 검색 순위와 최신 벡터 검색 순위를 결합하여 계산된 통합 점수입니다. 서로 다른 검색 알고리즘의 장점을 합쳐 최적의 결과를 도출합니다.

## 5. 왜 RAG가 필요한가?

1.  **신뢰성(Reliability)**: 시스템 내부에 실제 존재하는 도서 데이터를 근거로 답변하므로 거짓 정보를 말할 확률이 현격히 낮아집니다.
2.  **최신성(Up-to-date)**: AI 모델을 매번 다시 학습(Fine-tuning)시키지 않아도, DB에 저장된 최신 도서 정보를 즉시 답변에 반영할 수 있습니다.
3.  **투명성(Transparency)**: 어떤 데이터를 참고해서 답변했는지 출처(Context)를 명확히 제시할 수 있습니다.

## 4. 기술 스택: Spring AI & Gemini
본 프로젝트에서는 RAG를 구현하기 위해 다음과 같은 기술을 사용합니다.

### 4.1. 주요 의존성 (pom.xml)
RAG 구현을 위해 `pom.xml`에 다음 의존성을 추가해야 합니다.

```xml
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-starter-model-google-genai</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-openai</artifactId>
</dependency>
```

*   **spring-ai-starter-model-google-genai**: Google의 Gemini 모델을 사용하기 위한 핵심 라이브러리입니다. `ChatModel`을 통해 텍스트 생성 및 RAG 응답을 처리합니다.
*   **spring-ai-openai**: OpenAI 표준 API를 지원하는 라이브러리입니다. 본 프로젝트에서는 텍스트를 수치화하는 **Embedding 모델** 연동을 위해 사용합니다. (OpenAI 호환 API 서버를 활용)

### 4.2. 구성 요소
- **Spring AI**: AI 모델과 연동하기 위한 스프링 공식 프레임워크입니다. 표준화된 인터페이스를 제공하여 다양한 AI 모델(OpenAI, Gemini 등)을 손쉽게 교체할 수 있습니다.
- **Google Gemini**: 구글의 최신 대규모 언어 모델(LLM)입니다. 여기서는 `gemini-2.0-flash` 모델을 사용하여 빠르고 정확한 응답을 생성합니다.

## 5. 학습 포인트

*   **AI의 한계 인식**: LLM이 모든 것을 알고 있다는 오해에서 벗어나, 기술적인 보완이 필요한 지점을 이해합니다.
*   **검색의 역할 변화**: 지금까지 구현한 '검색' 기능이 단순히 사용자에게 리스트를 보여주는 것을 넘어, AI의 '참고 자료'로 활용되는 과정을 학습합니다.

## 5. 심화 학습 (Study Topics)

### 5.1. 오픈북 테스트 (RAG)
RAG는 AI에게 **'정답이 들어있는 참고서'** 를 건네주는 과정입니다.
- **비유**: 친구에게 "우리 도서관에서 제일 재미있는 요리책 추천해줘"라고 물었을 때, 친구가 기억에만 의존하지 않고 도서관 검색기에서 평점이 높은 책들을 찾아본 뒤 그 내용을 요약해서 알려주는 것과 같습니다.

### 5.2. 지식의 유통기한
세상에 매일같이 쏟아지는 신간 도서 정보를 AI 모델이 실시간으로 학습하는 것은 불가능합니다. RAG는 모델의 머릿속 지식을 바꾸는 대신, 모델의 눈앞에 최신 데이터를 보여주는 전략입니다.

## 6. 참고 링크

*   [What is RAG? (IBM)](https://research.ibm.com/blog/retrieval-augmented-generation-RAG)
*   [RAG vs Fine-tuning (Microsoft)](https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview)
*   [AWS - RAG란 무엇입니까?](https://aws.amazon.com/ko/what-is/retrieval-augmented-generation/)
